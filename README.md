# MULTITAN-WMT2025-Terminology

Lichao Zhu, Maria Zimina-Poirot, Stéphane Patin & Cristian Valdez\
ALTAE, University Paris Cité

## Training data augmentation by proper terminology
  1. Development set using the ELRC English–Spanish corpora
  2. AI-driven data augmentation via few‑shot prompting
  3. MarianMT
     - hard-forced decoding with glossary (placeholder strategy)
     - Standard fine‑tuning with filtering and corpora quality control
  4. LoRA fine‑tuning of EuroLLM with integrated glossary prompting
  5. Model Studio Lite fine‑tuning with glossary injection

## Collocations and contextual variations of terms
  Analysis 
